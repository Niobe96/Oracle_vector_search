import os
import cv2
import numpy as np
import torch
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
import faiss
import pickle
from tqdm import tqdm
import shutil
from glob import glob
import yaml

# --- âš™ï¸ 1. ì„¤ì • (Configuration) ---
# ìŠ¤í¬ë¦½íŠ¸ê°€ ì‹¤í–‰ë˜ëŠ” ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì„¤ì •
BASE_PROJECT_DIR = os.path.dirname(os.path.abspath(__file__))

# ì…ë ¥ ê²½ë¡œ
ORIGINAL_BASE_DIR = os.path.join(BASE_PROJECT_DIR, 'data', 'raw', 'Brain_MRI')

# âœ… ì¤‘ê°„ ìƒì„±ë¬¼ ê²½ë¡œ ì´ë¦„ ë³€ê²½ (ì ìš©ëœ ì „ì²˜ë¦¬ ë°©ì‹ ëª…ì‹œ)
PROCESSED_BASE_DIR = os.path.join(BASE_PROJECT_DIR, 'data', 'processed', 'Brain_MRI_GammaBlur')
OUTPUT_DIR = os.path.join(BASE_PROJECT_DIR, 'output')
CROPPED_IMAGES_DIR = os.path.join(OUTPUT_DIR, 'cropped_images')

# ìµœì¢… ìì‚° ê²½ë¡œ (app.pyê°€ ì‚¬ìš©í•  íŒŒì¼ë“¤)
ASSETS_DIR = os.path.join(BASE_PROJECT_DIR, 'assets')
FAISS_INDEX_PATH = os.path.join(ASSETS_DIR, 'tumor_db.index')
METADATA_PKL_PATH = os.path.join(ASSETS_DIR, 'metadata.pkl')

# ì¶œë ¥ í´ë”ë“¤ ìƒì„±
os.makedirs(PROCESSED_BASE_DIR, exist_ok=True)
os.makedirs(CROPPED_IMAGES_DIR, exist_ok=True)
os.makedirs(ASSETS_DIR, exist_ok=True)

# ê°ë§ˆ ë³´ì • í•˜ì´í¼íŒŒë¼ë¯¸í„°
GAMMA = 1.5


# --- ğŸ–¼ï¸ 2. âœ… ê°ë§ˆ ë³´ì • + ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ ì „ì²˜ë¦¬ í•¨ìˆ˜ (CLAHE ëŒ€ì²´) ---
def preprocess_dataset_with_gamma_blur(original_base_path, new_base_path, gamma_value):
    """
    ì›ë³¸ ë°ì´í„°ì…‹ì˜ ëª¨ë“  ì´ë¯¸ì§€ì— ê°ë§ˆ ë³´ì •ê³¼ ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¥¼ ì ìš©í•˜ê³ ,
    ìƒˆë¡œìš´ ê²½ë¡œì— ì €ì¥í•˜ë©° ë¼ë²¨ íŒŒì¼ê³¼ YAML íŒŒì¼ì„ ë³µì‚¬/ìˆ˜ì •í•©ë‹ˆë‹¤.
    """
    print(f"ğŸš€ --- Starting Gamma Correction + Gaussian Blur Preprocessing --- ğŸš€")
    if not os.path.exists(original_base_path):
        print(f"âŒ CRITICAL ERROR: Original dataset not found at '{original_base_path}'")
        print("Please check the ORIGINAL_BASE_DIR path.")
        exit() # í”„ë¡œê·¸ë¨ ì¢…ë£Œ

    # ê°ë§ˆ ë³´ì •ì„ ìœ„í•œ ë£©ì—… í…Œì´ë¸” ìƒì„±
    inv_gamma = 1.0 / gamma_value
    table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in range(256)]).astype("uint8")

    for split in ['train', 'valid', 'test']:
        source_img_dir = os.path.join(original_base_path, split, 'images')
        target_img_dir = os.path.join(new_base_path, split, 'images')
        source_lbl_dir = os.path.join(original_base_path, split, 'labels')
        target_lbl_dir = os.path.join(new_base_path, split, 'labels')

        os.makedirs(target_img_dir, exist_ok=True)

        if not os.path.exists(source_img_dir):
            print(f"âš ï¸ Source directory not found, skipping: {source_img_dir}")
            continue

        print(f"\nProcessing '{split}' images...")
        image_paths = glob(os.path.join(source_img_dir, '*.*'))
        for img_path in tqdm(image_paths, desc=f"Applying Gamma+Blur to {split}"):
            img = cv2.imread(img_path)
            if img is None: continue

            # 1. ê°ë§ˆ ë³´ì • ì ìš© (ë£©ì—… í…Œì´ë¸” ì‚¬ìš©)
            gamma_img = cv2.LUT(img, table)

            # 2. ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ ì ìš© (ë…¸ì´ì¦ˆ ì œê±°)
            blur_img = cv2.GaussianBlur(gamma_img, (3, 3), 0)
            
            # ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ì €ì¥
            target_path = os.path.join(target_img_dir, os.path.basename(img_path))
            cv2.imwrite(target_path, blur_img)

        # ë¼ë²¨ íŒŒì¼ ë³µì‚¬ (ê¸°ì¡´ CLAHE í•¨ìˆ˜ì™€ ë™ì¼í•œ ë¡œì§)
        if os.path.exists(source_lbl_dir):
            # ëŒ€ìƒ í´ë”ê°€ ì´ë¯¸ ìˆìœ¼ë©´ ì‚­ì œ í›„ ìƒˆë¡œ ë³µì‚¬
            if os.path.exists(target_lbl_dir):
                shutil.rmtree(target_lbl_dir)
            shutil.copytree(source_lbl_dir, target_lbl_dir)

    # data.yaml íŒŒì¼ ë³µì‚¬ ë° ê²½ë¡œ ìˆ˜ì •
    original_yaml_path = os.path.join(original_base_path, 'data.yaml')
    new_yaml_path = os.path.join(new_base_path, 'data.yaml')
    if os.path.exists(original_yaml_path):
        try:
            with open(original_yaml_path, 'r') as f: data_yaml = yaml.safe_load(f)
            # 'path' í‚¤ê°€ ì¡´ì¬í•˜ë©´ ìƒˆë¡œìš´ ì „ì²˜ë¦¬ í´ë”ì˜ ì ˆëŒ€ ê²½ë¡œë¡œ ì—…ë°ì´íŠ¸
            if 'path' in data_yaml:
                data_yaml['path'] = os.path.relpath(new_base_path, BASE_PROJECT_DIR)
            with open(new_yaml_path, 'w') as f: yaml.dump(data_yaml, f)
        except Exception as e:
            print(f"Could not process data.yaml file: {e}")

    print(f"\nğŸ‰ --- Gamma+Blur Preprocessing Complete. Processed dataset at: {new_base_path} --- ğŸ‰")


# --- ğŸ§  3. ResNet-18 íŠ¹ì§• ì¶”ì¶œê¸° ì¤€ë¹„ (ë³€ê²½ ì—†ìŒ) ---
def get_feature_extractor(device):
    """ë¯¸ë¦¬ í•™ìŠµëœ ResNet-18 ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ íŠ¹ì§• ì¶”ì¶œê¸°ë¡œ ë§Œë“­ë‹ˆë‹¤."""
    model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
    model.fc = torch.nn.Identity() # ë§ˆì§€ë§‰ ë¶„ë¥˜ ë ˆì´ì–´ ì œê±°
    model.eval()
    model.to(device)
    return model

def get_preprocessor():
    """ImageNet í‘œì¤€ ì „ì²˜ë¦¬ë¥¼ ì •ì˜í•©ë‹ˆë‹¤."""
    return transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])

def extract_features_from_array(image_array, model, preprocessor, device):
    """OpenCV ì´ë¯¸ì§€ ë°°ì—´ì—ì„œ ì§ì ‘ íŠ¹ì§• ë²¡í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    img = cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB)
    img = Image.fromarray(img)
    img_t = preprocessor(img)
    batch_t = torch.unsqueeze(img_t, 0).to(device)
    with torch.no_grad():
        features = model(batch_t)
    return features.squeeze().cpu().numpy()


# --- ğŸš€ 4. ë©”ì¸ ì‹¤í–‰ ë¡œì§ ---
def run_build_pipeline():
    # âœ… ë‹¨ê³„ A: ê°ë§ˆ+ë¸”ëŸ¬ ì „ì²˜ë¦¬ ì‹¤í–‰ (ìˆ˜ì •ë¨)
    preprocess_dataset_with_gamma_blur(ORIGINAL_BASE_DIR, PROCESSED_BASE_DIR, GAMMA)

    # ë‹¨ê³„ B: FAISS DB êµ¬ì¶• ì¤€ë¹„ (ë³€ê²½ ì—†ìŒ)
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"\n\nğŸš€ --- Starting FAISS DB Creation --- ğŸš€")
    print(f"Using device: {device}")

    feature_extractor = get_feature_extractor(device)
    preprocessor = get_preprocessor()

    all_vectors = []
    all_metadata = []

    # âœ… ë‹¨ê³„ C: Gamma+Blur ì²˜ë¦¬ëœ ë°ì´í„°ì—ì„œ íŠ¹ì§• ì¶”ì¶œ (ì…ë ¥ ì†ŒìŠ¤ë§Œ ë³€ê²½ë¨)
    for split in ['train', 'valid', 'test']:
        print(f"\nProcessing Gamma+Blur'd '{split}' split for feature extraction...")
        
        image_dir = os.path.join(PROCESSED_BASE_DIR, split, 'images')
        label_dir = os.path.join(PROCESSED_BASE_DIR, split, 'labels')

        if not os.path.exists(image_dir): continue

        image_files = os.listdir(image_dir)
        for image_name in tqdm(image_files, desc=f"Extracting features from {split}"):
            if not image_name.lower().endswith(('.png', '.jpg', '.jpeg')): continue

            image_path = os.path.join(image_dir, image_name)
            label_path = os.path.join(label_dir, os.path.splitext(image_name)[0] + '.txt')

            if not os.path.exists(label_path): continue
            
            image = cv2.imread(image_path)
            if image is None: continue
            
            h_orig, w_orig, _ = image.shape

            with open(label_path, 'r') as f:
                for i, line in enumerate(f.readlines()):
                    try:
                        parts = line.strip().split()
                        class_id = int(parts[0])
                        x_center, y_center, width, height = map(float, parts[1:])
                        
                        w_abs, h_abs = int(width * w_orig), int(height * h_orig)
                        x1, y1 = int((x_center * w_orig) - (w_abs / 2)), int((y_center * h_orig) - (h_abs / 2))
                        x2, y2 = x1 + w_abs, y1 + h_abs
                        
                        cropped_image = image[y1:y2, x1:x2]
                        if cropped_image.size == 0: continue

                        feature_vector = extract_features_from_array(cropped_image, feature_extractor, preprocessor, device)
                        
                        cropped_filename = f"{os.path.splitext(image_name)[0]}_box{i}.jpg"
                        cropped_path = os.path.join(CROPPED_IMAGES_DIR, cropped_filename)
                        cv2.imwrite(cropped_path, cropped_image)

                        metadata = {
                            'class_id': class_id,
                            'original_path': os.path.relpath(image_path, BASE_PROJECT_DIR),
                            'cropped_path': os.path.relpath(cropped_path, BASE_PROJECT_DIR),
                            'coords': [x1, y1, x2, y2]
                        }
                        all_vectors.append(feature_vector)
                        all_metadata.append(metadata)
                    except Exception as e:
                        print(f"\nError processing {label_path}, line '{line.strip()}': {e}")

    # ë‹¨ê³„ D: FAISS ì¸ë±ìŠ¤ ìƒì„± ë° ì €ì¥ (ë³€ê²½ ì—†ìŒ)
    if not all_vectors:
        print("\nâŒ No features were extracted. FAISS DB creation aborted.")
        return

    print(f"\nBuilding FAISS index with {len(all_vectors)} vectors...")
    vector_db = np.array(all_vectors).astype('float32')
    d = vector_db.shape[1] # ResNet18 -> 512

    index = faiss.IndexFlatIP(d)
    faiss.normalize_L2(vector_db)
    index.add(vector_db)

    faiss.write_index(index, FAISS_INDEX_PATH)
    print(f"âœ… FAISS index saved to: {FAISS_INDEX_PATH} (Total vectors: {index.ntotal})")

    with open(METADATA_PKL_PATH, "wb") as f:
        pickle.dump(all_metadata, f)
    print(f"âœ… Metadata list saved to: {METADATA_PKL_PATH}")
    print("\nğŸ‰ --- All Preprocessing and DB Creation Processes Complete --- ğŸ‰")


# --- ğŸš€ 5. ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ---
if __name__ == '__main__':
    run_build_pipeline()
